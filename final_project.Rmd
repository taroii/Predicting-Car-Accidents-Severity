---
title: "final_project"
output: html_document
date: "2022-11-16"
---

# Car Accidents Project

### Part 1: Cleaning Data

##### Importing Data

```{r}
acc_train <- read.csv("Acctrain.csv", header=T, stringsAsFactors = T)
acc_test_x <- read.csv("AcctestNoYNew.csv", header=T, stringsAsFactors = T)
acc_test_x <- acc_test_x[, -1]
acc_sample <- read.csv("AccSampleNew.csv", header=T)
```

##### Understanding Missing Values Part 1 (Uncleaned Data)

```{r}
library(VIM)
library(dplyr)
library(ggplot2)
library(forcats)

#VIM::aggr() counts the number of missing values of each predictor and vizualises it
NA_plot_0 <- aggr(acc_train, only.miss=T, combined=F, numbers=T, sortVars=T, labels=names(acc_train), cex.axis=0.5, ylab=c("Missing Data", "Pattern"))

#Create a separate object for the table of missing values
NA_df_0 <- NA_plot_0$missings %>% filter(Count > 0) %>% arrange(desc(Count))
predictor_classes_0 <- data.frame("Variable"=names(acc_train), "Type" = sapply(acc_train, class))
NA_df_0 <- NA_df_0 %>% inner_join(predictor_classes_0, by="Variable") %>% 
              mutate(Proportion = Count / 35000 * 100)
NA_df_0$Type[NA_df_0$Type == "integer"] <- "numeric"


#Plot NA_df_0
head(NA_df_0, 17) %>% ggplot(aes(x=fct_rev(fct_reorder(Variable, Proportion)), y=Proportion, fill=Type)) + geom_col() +
  theme_bw() + labs(x="", y="% Missing Values") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = c(0.9, 0.8),
        legend.background = element_rect(size=0.5, linetype="solid", color="black")) 
```

The NA_df_0 dataframe shows the predictors with missing values arranged in descending order by missing value count. From this, we observe that the majority of missing values come from the weather-related predictors. 

##### Cleaning Training Data

```{r}
library(dplyr)
library(tidyr)

#Replacing Description with Dummy Variables

acc_train$Closure <- grepl("close", acc_train$Description, ignore.case=TRUE) |
  grepl("reduce", acc_train$Description, ignore.case=TRUE) | 
  grepl("block", acc_train$Description, ignore.case=TRUE)

acc_train$contains_accident <- grepl("accident", acc_train$Description, ignore.case=T)
acc_train$contains_incident <- grepl("incident", acc_train$Description, ignore.case=T)
acc_train$contains_traffic <- grepl("traffic", acc_train$Description, ignore.case=T)
acc_train$contains_slow <- grepl("slow", acc_train$Description, ignore.case=T)
acc_train$contains_caution <- grepl("caution", acc_train$Description, ignore.case=T)
acc_train$contains_closed <- grepl("closed", acc_train$Description, ignore.case=T)
acc_train$contains_blocked <- grepl("blocked", acc_train$Description, ignore.case=T)
acc_train$contains_road <- grepl("road", acc_train$Description, ignore.case=T)
acc_train$contains_exit <- grepl("exit", acc_train$Description, ignore.case=T)
acc_train$contains_lane <- grepl("lane", acc_train$Description, ignore.case=T)
acc_train$contains_due <- grepl("due", acc_train$Description, ignore.case=T)


#######################################################################################

#Create Month predictor, Year predictor, isWinter predictor, Hour predictor, Night predictor, and translate Time Predictors

acc_train$Month <- substr(acc_train[, 3], start=6, stop=7)
acc_train$Month <- as.numeric(acc_train$Month)

acc_train$Year <- substr(acc_train[, 3], start=1, stop=4)
acc_train$Year <- as.factor(acc_train$Year)

acc_train$Hour <- substr(acc_train[,3], start=12, stop=13)
acc_train$Hour <- as.numeric(acc_train$Hour)
acc_train$Night <- ifelse(acc_train$Hour > 18 | acc_train$Hour < 7, "Night", "Day")

stat_mode <- function(x) {
  if(any(is.na(x))){
    x[!is.na(x)]
  }
  else{
    ux <- unique(x)
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)][1]
  }
}

acc_train$Night <- as.factor(unlist(apply(acc_train[,c("Sunrise_Sunset", "Civil_Twilight", "Nautical_Twilight", "Astronomical_Twilight", "Night")], 1, stat_mode)))

acc_train[,c(2, 3, 19)] <- apply(acc_train[, c(2, 3, 19)], 2, as.character)
acc_train[,c(2, 3, 19)] <- apply(acc_train[, c(2, 3, 19)], 2, as.POSIXct, format="%Y-%m-%dT%H:%M:%SZ")

#######################################################################################

#Cleaning Wind_Direction

x <- as.character(acc_train$Wind_Direction)
x[x == "CALM"] <- "Calm"
x[x=="East"] <- "E"
x[x=="North"] <- "N"
x[x=="South"] <- "S"
x[x=="West"] <- "W"
x[x=="Variable"] <- "VAR"
acc_train$Wind_Direction <- as.factor(x)

#######################################################################################

#Create Highway Predictor
#(Whether or not the accident occurred on a highway)

acc_train$Highway <- grepl("Hwy", acc_train$Street, ignore.case=TRUE) | grepl("Highway", acc_train$Street, ignore.case=TRUE) |grepl("I-", acc_train$Street, ignore.case=TRUE)


#######################################################################################

#Create Time_Lapsed Predictor

acc_train$Time_Lapsed <- acc_train$End_Time - acc_train$Start_Time


#Create Distance_Traveled Predictor

acc_train <- acc_train %>% mutate("Distance_Traveled" = sqrt((End_Lat - Start_Lat)^2 + (End_Lng - Start_Lng)^2))

#######################################################################################

#Simplify Zipcode

acc_train$Zipcode <- as.factor(sapply(acc_train$Zipcode, substr, start=1, stop=5))

#Organize zipcodes into 9 regional categories (Region_Code)

region <- data.frame("Region_Code" = 0:9, "Region" = as.factor(c('New England', 'Mid-Atlantic', 'Central East Coast', 'South', 'Midwest', 'Northern Great Plains', 'Central Great Plains', 'South Central', 'Mountain Desert', 'West Coast')))

acc_train <- acc_train %>% mutate("Region_Code" = as.factor(substr(Zipcode, 1, 1)))

#acc_train <- merge(acc_train, region, all.x=T, all.y=F, by.x="Region_Code", by.y="Region_Code")

acc_train$Region_Code <- as.factor(acc_train$Region_Code)

#######################################################################################

#Create isCalm and isClear Predictors
#isCalm is a variable that indicates whether the Wind_Direction variable is "Calm". 
#isClear is a variable that indicates whether the Weather_Condition variable is "Clear". 

acc_train$isCalm <- acc_train$Wind_Direction == "CALM"
acc_train$isCalm[is.na(acc_train$isCalm)] <- FALSE

acc_train$isClear <- acc_train$Weather_Condition == "Clear"
acc_train$isClear[is.na(acc_train$isClear)] <- FALSE

#######################################################################################

#Remove redundant variables
#These variables are the variables the predictors we've just created are based on and variables with too many levels. 

#These variable are County, Start_Time, End_Time, Start_Lat, End_Lat, Start_Lng, End_Lng, Description, Street, City, State, Zipcode, Country, Airport_Code, Wind_Direction, Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight, Timezone, and Turning_Loop

non_redundant <- acc_train %>% select(-c(County, Start_Time, End_Time, Start_Lat, End_Lat, Start_Lng, End_Lng, Description, Street, City, State, Zipcode, Country, Airport_Code, Wind_Direction, Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight, Timezone, Turning_Loop))

#Export files
#write.csv(acc_train, "all_predictors.csv", row.names=F)
#write.csv(non_redundant, "non_redundant.csv", row.names=F)

#View new data frame
#str(non_redundant)
```

##### Cleaning Testing Data (Repeat of Previous Part)

```{r}
#Converting Description into a categorical predictor.
#Finding frequently used words in the descriptions of severe car accidents. 

#acc_train[acc_train$Severity == "SEVERE", ]$Description

#Commonly used words for severe accidents are closed, reduced, blocked.

acc_test_x$Closure <- grepl("close", acc_test_x$Description, ignore.case=TRUE) |
  grepl("reduce", acc_test_x$Description, ignore.case=TRUE) | 
  grepl("block", acc_test_x$Description, ignore.case=TRUE)

acc_test_x$contains_accident <- grepl("accident", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_incident <- grepl("incident", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_traffic <- grepl("traffic", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_slow <- grepl("slow", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_caution <- grepl("caution", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_closed <- grepl("closed", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_blocked <- grepl("blocked", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_road <- grepl("road", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_exit <- grepl("exit", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_lane <- grepl("lane", acc_test_x$Description, ignore.case=T)
acc_test_x$contains_due <- grepl("due", acc_test_x$Description, ignore.case=T)

#######################################################################################

#Create Month predictor, Year predictor, isWinter predictor, Hour predictor, Night predictor, and translate Time Predictors

acc_test_x$Month <- substr(acc_test_x[, 1], start=6, stop=7)
acc_test_x$Month <- as.numeric(acc_test_x$Month)

acc_test_x$Year <- substr(acc_test_x[, 1], start=1, stop=4)
acc_test_x$Year <- as.factor(acc_test_x$Year)

acc_test_x$Hour <- substr(acc_test_x[,1], start=12, stop=13)
acc_test_x$Hour <- as.numeric(acc_test_x$Hour)
acc_test_x$Night <- ifelse(acc_test_x$Hour > 18 | acc_test_x$Hour < 7, "Night", "Day")

stat_mode <- function(x) {
  if(any(is.na(x))){
    x[!is.na(x)]
  }
  else{
    ux <- unique(x)
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)][1]
  }
}

acc_test_x$Night <- as.factor(unlist(apply(acc_test_x[,c("Sunrise_Sunset", "Civil_Twilight", "Nautical_Twilight", "Astronomical_Twilight", "Night")], 1, stat_mode)))

acc_test_x[,c(1, 2, 18)] <- apply(acc_test_x[, c(1, 2, 18)], 2, as.character)
acc_test_x[,c(1, 2, 18)] <- apply(acc_test_x[, c(1, 2, 18)], 2, as.POSIXct, format="%Y-%m-%dT%H:%M:%SZ")

#######################################################################################

#Cleaning Wind_Direction

x <- as.character(acc_test_x$Wind_Direction)
x[x == "CALM"] <- "Calm"
x[x=="East"] <- "E"
x[x=="North"] <- "N"
x[x=="South"] <- "S"
x[x=="West"] <- "W"
x[x=="Variable"] <- "VAR"
acc_test_x$Wind_Direction <- as.factor(x)

#######################################################################################

#Create Highway Predictor
#(Whether or not the accident occurred on a highway)

acc_test_x$Highway <- grepl("Hwy", acc_test_x$Street, ignore.case=TRUE) | grepl("Highway", acc_test_x$Street, ignore.case=TRUE) |grepl("I-", acc_test_x$Street, ignore.case=TRUE)


#######################################################################################

#Create Time_Lapsed Predictor

acc_test_x$Time_Lapsed <- acc_test_x$End_Time - acc_test_x$Start_Time


#Create Distance_Traveled Predictor

acc_test_x <- acc_test_x %>% mutate("Distance_Traveled" = sqrt((End_Lat - Start_Lat)^2 + (End_Lng - Start_Lng)^2))

#######################################################################################

#Simplify Zipcode

acc_test_x$Zipcode <- as.factor(sapply(acc_test_x$Zipcode, substr, start=1, stop=5))

#Organize zipcodes into 9 regional categories (Region_Code)

region <- data.frame("Region_Code" = 0:9, "Region" = as.factor(c('New England', 'Mid-Atlantic', 'Central East Coast', 'South', 'Midwest', 'Northern Great Plains', 'Central Great Plains', 'South Central', 'Mountain Desert', 'West Coast')))

acc_test_x <- acc_test_x %>% mutate("Region_Code" = as.factor(substr(Zipcode, 1, 1)))

#acc_test_x <- merge(acc_test_x, region, all.x=T, all.y=F, by.x="Region_Code", by.y="Region_Code")

acc_test_x$Region_Code <- as.factor(acc_test_x$Region_Code)

#######################################################################################

#Create isCalm and isClear Predictors
#isCalm is a variable that indicates whether the Wind_Direction variable is "Calm". 
#isClear is a variable that indicates whether the Weather_Condition variable is "Clear". 

acc_test_x$isCalm <- acc_test_x$Wind_Direction == "CALM"
acc_test_x$isCalm[is.na(acc_test_x$isCalm)] <- FALSE

acc_test_x$isClear <- acc_test_x$Weather_Condition == "Clear"
acc_test_x$isClear[is.na(acc_test_x$isClear)] <- FALSE

#######################################################################################

#Remove redundant variables
#These variables are the variables the predictors we've just created are based on. 
#These variable are County, Start_Time, End_Time, Start_Lat, End_Lat, Start_Lng, End_Lng, Description, Street, City, State, Zipcode, Country, Airport_Code, Wind_Direction, Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight

test_simplified <- acc_train %>% select(-c(County, Start_Time, End_Time, Start_Lat, End_Lat, Start_Lng, End_Lng, Description, Street, City, State, Zipcode, Country, Airport_Code, Wind_Direction, Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight, Timezone, Turning_Loop))

#Export files
#write.csv(acc_test_x, "all_test.csv", row.names=F)
#write.csv(test_simplified, "simplified_test.csv", row.names=F)

#View new data frames
#str(test_simplified)
```



------------------------------------------------------------------------



### Part 2: Imputing Missing Values

##### Understanding Missing Values Part 2 (Cleaned Data)

```{r}
library(VIM)
library(dplyr)

#VIM::aggr() counts the number of missing values of each predictor and vizualises it
NA_plot <- aggr(non_redundant, only.miss=T, combined=T, numbers=T, sortVars=T, labels=names(non_redundant), cex.axis=0.5, ylab=c("Pattern"))

#Create a separate object for the table of missing values
NA_df <- NA_plot$missings %>% filter(Count > 0) %>% arrange(desc(Count))
predictor_classes <- data.frame("Variable"=names(non_redundant), "Type" = sapply(non_redundant, class))
NA_df <- NA_df %>% inner_join(predictor_classes, by="Variable")
#head(NA_df)

sum(NA_df$Count)

#Separate numeric and categorical columns with missing values
numeric_NAs <- NA_df %>% filter(Type == "numeric" | Type == "integer") %>% select(Variable) %>% unlist()
categorical_NAs <- NA_df %>% filter(Type == "factor") %>% select(Variable) %>% unlist()
```



##### Repeat for Testing Data

```{r}
#VIM::aggr() counts the number of missing values of each predictor and vizualises it
NA_plot_test <- aggr(test_simplified, only.miss=T, combined=T, numbers=T, sortVars=T, labels=names(test_simplified), cex.axis=0.5, ylab=c("Missing Data", "Pattern"))

#Create a separate object for the table of missing values
NA_df_test <- NA_plot_test$missings %>% filter(Count > 0) %>% arrange(desc(Count))
predictor_classes_test <- data.frame("Variable"=names(test_simplified), "Type" = sapply(test_simplified, class))
NA_df_test <- NA_df_test %>% inner_join(predictor_classes_test, by="Variable")
#head(NA_df_test)

#Separate numeric and categorical columns with missing values
numeric_NAs_test <- NA_df_test %>% filter(Type == "numeric" | Type == "integer") %>% select(Variable) %>% unlist()
categorical_NAs_test <- NA_df_test %>% filter(Type == "factor") %>% select(Variable) %>% unlist()
```


##### Hmisc Imputation

The Hmisc Approach includes 2 steps:

1.  Imputing numeric missing values with the median and categorical missing values with the mode.

2.  Imputing missing values with additive regression, bootstrapping, and predictive mean matching imputation.

Training Data:

```{r}
library(Hmisc)

#First Approach:
#Simple median imputation
imputed_numerical <- as.data.frame(apply(non_redundant[, numeric_NAs], 2, impute, fun=median))
imputed_categorical <- sapply(non_redundant[, categorical_NAs], impute, fun=mode)

#Export Basic Imputed Dataset
train_imputed <- non_redundant
train_imputed[, numeric_NAs] <- imputed_numerical
train_imputed[, categorical_NAs] <- imputed_categorical
train_imputed$Year <- as.numeric(as.character(train_imputed$Year))

#Second Approach:
#Additive regression, bootstrapping, and predictive mean matching
train_areg <- non_redundant
train_areg <- aregImpute(Severity~I(Weather_Timestamp)+I(Temperature.F.)
                         +I(Wind_Chill.F.)+I(Humidity...)+I(Pressure.in.)+
                           I(Visibility.mi.)+I(Wind_Speed.mph.)+Region_Code, data=non_redundant, x=T)
areg_imputed <- non_redundant
areg_imputed[, unlist(NA_df$Variable)] <- as.data.frame(train_areg$x)[, -1]

#export file
#write.csv(areg_imputed, "areg_imputed_train.csv", row.names=F)
```

Testing Data:

```{r}
#First Approach:
#Simple median imputation
imputed_numeric_test <- as.data.frame(apply(test_simplified[, numeric_NAs], 2, impute, fun=median))
imputed_categorical_test <- sapply(test_simplified[, categorical_NAs], impute, fun=mode)

#Export Basic Imputed Dataset
test_imputed <- test_simplified
test_imputed[, numeric_NAs] <- imputed_numeric_test
test_imputed[, categorical_NAs] <- imputed_categorical_test
test_imputed$Year <- as.numeric(as.character(test_imputed$Year))

#Second Approach:
#Additive regression, bootstrapping, and predictive mean matching
test_areg <- test_simplified
test_areg <- aregImpute(Closure~I(Weather_Timestamp)+I(Temperature.F.)
                         +I(Wind_Chill.F.)+I(Humidity...)+I(Pressure.in.)+
                           I(Visibility.mi.)+I(Wind_Speed.mph.)+Region_Code, data=test_simplified, x=T)
areg_imputed_test <- test_simplified
areg_imputed_test[, unlist(NA_df$Variable)] <- as.data.frame(test_areg$x)[, -1]
#write.csv(areg_imputed_test, "areg_imputed_test.csv", row.names=F)
```


### Part 3: Classification Models

#### randomForest

```{r}
library(randomForest)

error_values <- c()

for (i in 34:44)
{
temp_model <- randomForest(Severity ~ ., data = areg_imputed, mtry = i, ntree = 500)
error_values[i - 33] <- temp_model$err.rate[nrow(temp_model$err.rate), 1]
}

which.min(error_values)

#best mtry is 37

model_rf <- randomForest(Severity~., train, mtry=37, importance=T, ntree=1000)

model_rf$importance

varImpPlot(model_rf, cex=0.7)

#partialPlot(model_rf, areg_imputed, Closure)

#MDSplot(model_rf)

#plot(model_rf)

rf_out <- predict(model_rf, areg_imputed_test)

rf_final <- data.frame("Ob" = 1:15000, "SEVERITY" = rf_out)

#write.csv(rf_final, "rf_submission.csv", row.names=F)
```


#### XGBoost

```{r}
library(xgboost)
library(caret)
library(ggplot2)
library(Ckmeans.1d.dp)
library(DiagrammeR)

model_xgboost <- train(Severity~., areg_imputed, method="xgbTree", trControl=trainControl("cv", 10))

xgb_model <- xgboost(train_converted[, -1], label=train$Severity, nrounds=50, eval_metric="mae", max_depth=4)

xgb_model$evaluation_log

xgb_imp <- xgb.importance(model=xgb_model)
xgb_imp

#plots

xgb.ggplot.importance(xgb_imp) + theme_bw()

dotchart(rev(xgb_imp$Importance)[1:29], labels=rev(xgb_imp$Feature[1:29]), cex=0.7, main="XGBoost", xlab="Importance")

xgb.plot.tree(feature_names = names(train[, -1]), model=xgb_model, trees=10)


train_converted <- sapply(train, as.numeric)

xgboost_out <- predict(model_xgboost, areg_imputed_test)

xgboost_final <- data.frame("Ob" = 1:15000, "SEVERITY" = xgboost_out)

#write.csv(xgboost_final, "xgboost_submission.csv", row.names=F)
```

#### kNN

```{r}
library(class)
library(stats)

#Prep Data
Y_train <- areg_imputed$Severity
X_train <- areg_imputed[, -1]
indx <- sapply(X_train, is.factor)
X_train[indx] <- lapply(X_train[indx], as.numeric)
X_train <- as.matrix(X_train)
#dim(X_train)

X_test <- areg_imputed_test
indx <- sapply(X_test, is.factor)
X_test[indx] <- lapply(X_test[indx], as.numeric)
X_test <- as.matrix(X_test)
#dim(X_test)

#Create kNN Models
model_knn10 <- knn(X_train, X_test, Y_train, k=10)
model_knn25 <- knn(X_train, X_test, Y_train, k=25)
model_knn50 <- knn(X_train, X_test, Y_train, k=50)

#Write Files
knn10_final <- data.frame("Ob"=1:15000, "SEVERITY" = model_knn10)
knn25_final <- data.frame("Ob"=1:15000, "SEVERITY" = model_knn25)
knn50_final <- data.frame("Ob"=1:15000, "SEVERITY" = model_knn50)

#write.csv(knn10_final, "knn10_submission.csv", row.names=F)
#write.csv(knn25_final, "knn25_submission.csv", row.names=F)
#write.csv(knn50_final, "knn50_submission.csv", row.names=F)

```




